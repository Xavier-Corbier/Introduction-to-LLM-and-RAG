# Session 1: Introduction to Large Language Models (LLMs)
## Part 2: Introduction to Responsible AI

### Introduction
Artificial intelligence (AI) powers many apps and services that people use in daily life. With billions of users of AI across fields from business to healthcare to education, it is critical that leading AI companies work to ensure that the benefits of these technologies outweigh the harms, in order to create the most helpful, safe, and trusted experiences for all.

Responsible AI considers the societal impact of the development and scale of these technologies, including potential harms and benefits. The [AI Principles](https://ai.google/responsibility/principles/) provide a framework that includes objectives for AI applications, and applications we will not pursue in the development of AI systems.

### Responsible AI Dimensions
As AI development accelerates and becomes more ubiquitous, it is critical to incorporate Responsible AI practices into every workflow stage from ideation to launch. The following dimensions are key components to Responsible AI, and are important to consider throughout the product lifecycle.

#### Fairness
Fairness addresses the possible disparate outcomes end users may experience as related to sensitive characteristics such as race, income, sexual orientation, or gender through algorithmic decision-making. For example, might a hiring algorithm have biases for or against applicants with names that are associated with a particular gender or ethnicity?

Learn more about how machine learning systems might be susceptible to human bias in this video:

<iframe width="865" height="486" src="https://www.youtube.com/embed/59bMh59JQDo" title="3 types of bias in AI | Machine learning" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>