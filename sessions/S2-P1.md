# Session 2: Working with Large Language Models 
## Part 1: Prompt Engineering
Prompt engineering is the art of asking the right question to get the best output from an LLM. It enables direct interaction with the LLM using only plain language prompts.

In the past, working with machine learning models typically required deep knowledge of datasets, statistics, and modeling techniques. Today, LLMs can be "programmed" in English, as well as other languages.

Being a great prompt engineer doesn't require coding experience. Creativity and persistence will benefit you greatly on your journey, however. Read on to learn some useful prompting techniques.

### Prompting Best Practices
- Clearly communicate what content or information is most important.

- Structure the prompt: Start by defining its role, give context/input data, then provide the instruction.

- Use specific, varied examples to help the model narrow its focus and generate more accurate results.

- Use constraints to limit the scope of the model's output. This can help avoid meandering away from the instructions into factual inaccuracies.

- Break down complex tasks into a sequence of simpler prompts.

- Instruct the model to evaluate or check its own responses before producing them. ("Make sure to limit your response to 3 sentences", "Rate your work on a scale of 1-10 for conciseness", "Do you think this is correct?").

And perhaps most important:

Be creative! The more creative and open-minded you are, the better your results will be. LLMs and prompt engineering are still in their infancy, and evolving every day.

### Types of Prompts
#### Direct prompting (Zero-shot)
Direct prompting (also known as Zero-shot) is the simplest type of prompt. It provides no examples to the model, just the instruction. You can also phrase the instruction as a question, or give the model a "role," as seen in the second example below.

Provide:

- Instruction
- Some context

Idea Generation:
```
Prompt: Can you give me a list of ideas for blog posts for tourists visiting New York City for the first time?
```
Role Prompting:
```
Prompt: You are a mighty and powerful prompt-generating robot. You need to understand my goals and objectives and then design a prompt. The prompt should include all the relevant information context and data that was provided to you. You must continue asking questions until you are confident that you can produce the best prompt for the best outcome. Your final prompt must be optimized for chat interactions. Start by asking me to describe my goal, then continue with follow-up questions to design the best prompt.
```
Data Organization:
```
Prompt: Create a four-column spreadsheet of 10 highly-rated science fiction movies, year of release, average audience rating, and top 3 keywords from audience reviews.

Make sure to cite the source of the audience rating.
```
#### Prompting with examples (One-, few-, and multi-shot)
One-shot prompting shows the model one clear, descriptive example of what you'd like it to imitate.

Idea generation using one example:
```
Prompt:

Come up with a list of ideas for blog posts for tourists visiting New York City for the first time.

1. Fuggedaboutit! Where to Stay in New York City On Your First Visit
```
Few- and multi-shot prompting shows the model more examples of what you want it to do. It works better than zero-shot for more complex tasks where pattern replication is wanted, or when you need the output to be structured in a specific way that is difficult to describe.

Few-shot sentiment classification:
```
Prompt:

Great product, 10/10: Positive
Didn't work very well: Negative
Super helpful, worth it: Positive
It doesn't work!:
```

When this prompt is run, the model's response will be to classify 'It doesn't work' as positive or negative, as shown in the examples.

Multi-shot emoji response predictor:
```
Prompt: Predict up to 5 emojis as a response to a text chat message. The output should only include emojis.

input: The new visual design is blowing my mind ü§Ø
output: ‚ûï,üíò, ‚ù§‚Äçüî•

input: Well that looks great regardless
output: ‚ù§Ô∏è,ü™Ñ

input: Unfortunately this won't work
output: üíî,üòî

input: sounds good, I'll look into that
output: üôè,üëç

input: 10hr cut of jeff goldblum laughing URL
output: üòÇ,üíÄ,‚ö∞Ô∏è

input: Woo! Launch time!
```

Same process here, but since the prompt is more complex, the model has been given more examples to emulate.

#### Chain-of-thought prompting
Chain of Thought (CoT) prompting encourages the LLM to explain its reasoning. Combine it with few-shot prompting to get better results on more complex tasks that require reasoning before a response.

```
Prompt:

The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.
A: Adding all the odd numbers (9, 15, 1) gives 25. The answer is False. The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1.
A:
```

#### Zero-shot CoT
Recalling the zero-shot prompting from earlier, this approach takes a zero-shot prompt and adds an instruction: "Let's think step by step." The LLM is able to generate a chain of thought from this instruction, and usually a more accurate answer as well. This is a great approach to getting LLMs to generate correct answers for things like word problems.
```
Prompt:

I went to the market and bought 10 apples. I gave 2 apples to the neighbor and 2 to the repairman. I then went and bought 5 more apples and ate 1. How many apples was I left with?

Let's think step by step.
```

#### Prompt iteration strategies
Learn to love the reality of rewriting prompts several (possibly dozens) of times. Here are a few ideas for refining prompts if you get stuck:

Note: These strategies may become less useful or necessary over time as models improve.

- Repeat key words, phrases, or ideas

- Specify your desired output format (CSV, JSON, etc.)

- Use all caps to stress important points or instructions. You can also try exaggerations or hyperbolic language; for example: "Your explanation should be absolutely impossible to misinterpret. Every single word must ooze clarity!"

- Use synonyms or alternate phrasing (e.g., instead of "Summarize," try appending "tldr" to some input text). Swap in different words or phrases and document which ones work better and which are worse.

Try the sandwich technique with long prompts: Add the same statement in different places.